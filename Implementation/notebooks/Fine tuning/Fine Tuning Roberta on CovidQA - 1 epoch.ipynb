{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d56b543",
   "metadata": {},
   "source": [
    "# About:\n",
    "- this notebook fine-tunes \"deepset/roberta-base-squad2\" on CovidQA over 1 epoch\n",
    "- this will be the final model used in the QA system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67391f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.reader.farm import FARMReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5598df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"deepset/roberta-base-squad2\"\n",
    "max_seq_len = 280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ed96fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/27/2021 21:46:29 - INFO - farm.utils -   Using device: CUDA \n",
      "06/27/2021 21:46:29 - INFO - farm.utils -   Number of GPUs: 1\n",
      "06/27/2021 21:46:29 - INFO - farm.utils -   Distributed Training: False\n",
      "06/27/2021 21:46:29 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2021/06/27 21:46:42 WARNING mlflow.tracking.context.git_context: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "06/27/2021 21:46:49 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "06/27/2021 21:46:49 - INFO - farm.utils -   Using device: CUDA \n",
      "06/27/2021 21:46:49 - INFO - farm.utils -   Number of GPUs: 1\n",
      "06/27/2021 21:46:49 - INFO - farm.utils -   Distributed Training: False\n",
      "06/27/2021 21:46:49 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "06/27/2021 21:46:49 - INFO - farm.infer -   Got ya 7 parallel workers to do inference ...\n",
      "06/27/2021 21:46:49 - INFO - farm.infer -    0    0    0    0    0    0    0 \n",
      "06/27/2021 21:46:49 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "06/27/2021 21:46:49 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "06/27/2021 21:46:49 - INFO - farm.infer -               \n"
     ]
    }
   ],
   "source": [
    "reader = FARMReader(model_name_or_path=model_name_or_path,\n",
    "                    batch_size = 5,\n",
    "                    max_seq_len = max_seq_len,\n",
    "                    use_gpu = True,\n",
    "                    doc_stride = 100,\n",
    "                    context_window_size = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea94ae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/27/2021 21:46:49 - INFO - farm.utils -   Using device: CUDA \n",
      "06/27/2021 21:46:49 - INFO - farm.utils -   Number of GPUs: 1\n",
      "06/27/2021 21:46:49 - INFO - farm.utils -   Distributed Training: False\n",
      "06/27/2021 21:46:49 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "Preprocessing Dataset C:\\Users\\tanch\\Documents\\GitHub\\URECA-CovidQA-Research\\Implementation\\SQUAD formatted data\\covidQ\n",
      "06/27/2021 21:47:07 - WARNING - farm.modeling.prediction_head -   Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "06/27/2021 21:47:07 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "06/27/2021 21:47:07 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "06/27/2021 21:47:07 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_training_steps': 527, 'num_warmup_steps': 105}'\n",
      "Train epoch 0/0 (Cur. train loss: 1.9339): 100%|█████████████████████████████████████| 527/527 [03:59<00:00,  2.20it/s]\n",
      "06/27/2021 21:51:07 - INFO - haystack.reader.farm -   Saving reader model to ..\\..\\saved_models\\deepset\\roberta-base-squad2\n"
     ]
    }
   ],
   "source": [
    "reader.train(data_dir = r\"C:\\Users\\tanch\\Documents\\GitHub\\URECA-CovidQA-Research\\Implementation\\SQUAD formatted data\",\n",
    "             train_filename = \"covidQA.json\", \n",
    "             max_seq_len = max_seq_len,\n",
    "             use_gpu = True, \n",
    "             batch_size = 5,\n",
    "             n_epochs = 1,\n",
    "             learning_rate = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b0fa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/27/2021 21:52:02 - INFO - haystack.reader.farm -   Saving reader model to C:\\Users\\tanch\\Documents\\GitHub\\URECA-CovidQA-Research\\Implementation\\Reader\n"
     ]
    }
   ],
   "source": [
    "reader.save(r\"C:\\Users\\tanch\\Documents\\GitHub\\URECA-CovidQA-Research\\Implementation\\Reader\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
