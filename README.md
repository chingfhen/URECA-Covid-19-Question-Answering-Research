# URECA-CovidQA-Research
This repository documents a URECA Question Answering research: https://github.com/chingfhen/URECA-Covid-19-Question-Answering-Research/blob/main/Covid-19%20Question%20Answering%20System%20FIN.pdf
  1. built a Covid-19 Question Answering System that answers Covid-19 Questions 
  2. compared the performances of 7 BERT architectures namely albert-base-v1, bert-base-cased, bert-base-uncased, distilbert-base-uncased, distilroberta-base, google/electra-base-discriminator, roberta-base over varying max_length

  - Implementation of Covid19 QA system: Implemetation->notebooks->Covid19 QA System

  - Covid19 document store: Implemetation->notebooks->Renew DocumentStore

  - Fine-tuning on CovidQA: Implemetation->notebooks->Fine-tuning

  - CovidQA Dataset: Implemetation->CovidQA dataset

  - Comparing reader models: Research->notebooks->Visualization - Model performances over varied max_length

  - Fine tuning reader models on SQuAD 1.1: Research->notebooks->Fine tuning


Skills and libraries learnt: Building Question Answering Systems, HuggingFace, Haystack, Fine-tuning question answering models, BERT architecture
